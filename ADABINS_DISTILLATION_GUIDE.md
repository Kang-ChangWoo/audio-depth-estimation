# AdaBins Knowledge Distillation Guide

**RGB â†’ Audio Knowledge Transfer with Adaptive Binning**

---

## ğŸ¯ Overview

ì´ ì‹œìŠ¤í…œì€ **RGBì—ì„œ í•™ìŠµí•œ depth estimation ëŠ¥ë ¥ì„ Audioë¡œ transfer**í•©ë‹ˆë‹¤.

### í•µì‹¬ ê°œë…

1. **AdaBins**: Scene-adaptive binningìœ¼ë¡œ ê° ì´ë¯¸ì§€ë§ˆë‹¤ ìµœì ì˜ depth bins ì˜ˆì¸¡
2. **Knowledge Distillation**: RGB Teacherê°€ Audio Studentë¥¼ ê°€ë¥´ì¹¨
3. **Independent Inference**: í•™ìŠµ í›„ Audioë§Œìœ¼ë¡œ ë…ë¦½ì ìœ¼ë¡œ depth ì˜ˆì¸¡

### ê¸°ì¡´ ë°©ì‹ê³¼ì˜ ì°¨ì´

| | ê¸°ì¡´ Base+Residual | Multi-Modal Fusion | **AdaBins Distillation** |
|---|---|---|---|
| Base ì˜ˆì¸¡ | Regression | Fusion | **Classification (Adaptive Bins)** |
| RGB ì‚¬ìš© | âŒ | Training + Inference | **Training only** |
| Inference | Audio only | RGB + Audio | **Audio only** |
| Scene Adaptation | âŒ | âŒ | **âœ… (Image-level)** |
| Knowledge Transfer | âŒ | Implicit | **âœ… (Explicit Distillation)** |

---

## ğŸ—ï¸ Architecture

### Training Phase

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Training Input                        â”‚
â”‚              RGB [B,3,H,W] + Audio [B,2,H,W]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  RGB Encoder     â”‚     â”‚ Audio Encoder  â”‚
    â”‚   (Teacher)      â”‚     â”‚  (Student)     â”‚
    â”‚  Pre-trained     â”‚     â”‚  Learning      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â”‚ Features               â”‚ Features
             â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Bin Predictor   â”‚     â”‚ Bin Predictor  â”‚
    â”‚  (Adaptive)      â”‚     â”‚  (Learning)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â”‚ Bins                   â”‚ Bins
             â”‚                        â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Decoder         â”‚     â”‚  Decoder       â”‚
    â”‚  (Classify)      â”‚     â”‚  (Classify)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                        â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Distillation Losses:       â”‚
         â”‚  1. Task (Audio vs GT)      â”‚
         â”‚  2. Response (Audio vs RGB) â”‚
         â”‚  3. Feature (Match Features)â”‚
         â”‚  4. Bin Distribution        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Inference Phase

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Audio [B,2,H,W]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚Audio Encoder â”‚  â† Learned from RGB!
    â”‚  (Student)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Bin Predictor    â”‚  â† Predicts adaptive bins
    â”‚  (Adaptive)      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Decoder    â”‚
    â”‚  (Classify)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Depth Map   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

RGB NOT NEEDED! âœ…
```

---

## ğŸ“Š Loss Functions

### 1. Task Loss (Audio vs GT)
```python
L_task = L1(audio_depth, gt_depth)
```
Audioê°€ ì •í™•í•œ depthë¥¼ ì˜ˆì¸¡í•˜ë„ë¡

### 2. Response Distillation (Audio vs RGB)
```python
L_response = MSE(audio_depth, rgb_depth.detach())
```
Audioê°€ RGBì˜ ìµœì¢… ì˜ˆì¸¡ì„ ëª¨ë°©í•˜ë„ë¡

### 3. Feature Distillation (Intermediate Features)
```python
L_feature = Î£ cosine_distance(audio_feat_i, rgb_feat_i.detach())
```
Audio featuresê°€ RGB featuresì™€ ìœ ì‚¬í•˜ë„ë¡

### 4. Bin Distribution Distillation
```python
L_bin = KL_div(audio_bins / T, rgb_bins.detach() / T) * TÂ²
```
Audioê°€ RGBì™€ ìœ ì‚¬í•œ bin distribution í•™ìŠµ (Temperature scaling)

### 5. Residual Sparsity
```python
L_sparse = |residual|
```
Base depthê°€ ëŒ€ë¶€ë¶„ì˜ ì¼ì„ í•˜ë„ë¡

### Total Loss
```python
L_total = Î»_taskÂ·L_task + Î»_responseÂ·L_response + 
          Î»_featureÂ·L_feature + Î»_binÂ·L_bin + Î»_sparseÂ·L_sparse
```

---

## ğŸ“ Training Strategies

### Strategy 1: Standard Distillation (ê³ ì • ê°€ì¤‘ì¹˜)

```bash
python train_adabins_distillation.py \
  --dataset batvisionv2 \
  --batch_size 64 \
  --learning_rate 0.001 \
  --n_bins 128 \
  --temperature 4.0 \
  --lambda_task 1.0 \
  --lambda_response 0.5 \
  --lambda_feature 0.3 \
  --lambda_bin 0.2 \
  --lambda_sparse 0.1 \
  --use_wandb
```

**ì–¸ì œ ì‚¬ìš©**: ê°„ë‹¨í•œ ì‹¤í—˜, ë¹ ë¥¸ iteration

### Strategy 2: Adaptive Distillation (Curriculum Learning)

```bash
python train_adabins_distillation.py \
  --dataset batvisionv2 \
  --batch_size 64 \
  --learning_rate 0.001 \
  --n_bins 128 \
  --use_adaptive_loss \
  --use_wandb \
  --experiment_name adaptive_distill
```

**Curriculum**: ì´ˆê¸°ì—” teacherì— ì˜ì¡´ â†’ í›„ê¸°ì—” ë…ë¦½ì  í•™ìŠµ

| Epoch Range | Î»_task | Î»_response | Î»_feature | Î»_bin |
|-------------|--------|------------|-----------|-------|
| 0-40        | 0.5    | 1.0        | 0.5â†’1.0   | 0.5   |
| 40-120      | 0.75   | 0.65       | 1.0â†’0.75  | 0.35  |
| 120-200     | 1.0    | 0.3        | 0.5       | 0.2   |

**ì–¸ì œ ì‚¬ìš©**: ì•ˆì •ì ì¸ ìˆ˜ë ´, ìµœì¢… ì„±ëŠ¥ ê·¹ëŒ€í™”

### Strategy 3: Frozen Teacher (ë¹ ë¥¸ í•™ìŠµ)

```bash
python train_adabins_distillation.py \
  --dataset batvisionv2 \
  --freeze_rgb \
  --temperature 6.0 \
  --lambda_response 0.8 \
  --use_wandb
```

**íŠ¹ì§•**: RGB teacher ê³ ì •, audioë§Œ í•™ìŠµ â†’ ë¹ ë¥¸ í•™ìŠµ

**ì–¸ì œ ì‚¬ìš©**: RGB teacherê°€ ì´ë¯¸ ì˜ í•™ìŠµë˜ì—ˆì„ ë•Œ

---

## ğŸš€ Quick Start

### 1. ê¸°ë³¸ í•™ìŠµ

```bash
cd /root/storage/implementation/shared_audio/Batvision-Dataset/UNetSoundOnly

# Standard distillation
python train_adabins_distillation.py \
  --dataset batvisionv2 \
  --batch_size 64 \
  --learning_rate 0.001 \
  --use_wandb \
  --experiment_name my_first_distillation
```

### 2. Adaptive í•™ìŠµ (ì¶”ì²œ!)

```bash
python train_adabins_distillation.py \
  --dataset batvisionv2 \
  --batch_size 64 \
  --learning_rate 0.001 \
  --use_adaptive_loss \
  --temperature 5.0 \
  --use_wandb \
  --experiment_name adaptive_v1
```

### 3. Custom ê°€ì¤‘ì¹˜

```bash
python train_adabins_distillation.py \
  --dataset batvisionv2 \
  --lambda_task 1.0 \
  --lambda_response 0.7 \
  --lambda_feature 0.5 \
  --lambda_bin 0.3 \
  --lambda_sparse 0.15 \
  --use_wandb
```

---

## ğŸ“ˆ Expected Results

### Performance Comparison

| Model | RMSE | ABS_REL | DELTA1 | Training | Inference |
|-------|------|---------|--------|----------|-----------|
| UNet Baseline | 3.5 | 0.25 | 0.65 | Audio only | Audio only |
| Base+Residual | 3.2 | 0.22 | 0.70 | Audio only | Audio only |
| **AdaBins Distill** | **2.8** | **0.18** | **0.78** | **RGB+Audio** | **Audio only** |
| Multi-Modal Fusion | 2.5 | 0.15 | 0.82 | RGB+Audio | **RGB+Audio** âš ï¸ |

**AdaBins Distillationì˜ ì¥ì :**
- âœ… Training: RGB knowledge í™œìš©
- âœ… Inference: Audioë§Œ í•„ìš” (ì‹¤ìš©ì !)
- âœ… Scene-adaptive binning
- âœ… Stable training (classification)

### Training Progress

```
Epoch 10:
  Task:     2.50  (Audio vs GT)
  Response: 0.80  (Audio vs RGB)
  Feature:  0.35  (Feature alignment)
  Sparse:   0.12  (Residual small)
  â†’ Audio learning basic structure from RGB

Epoch 50:
  Task:     1.80
  Response: 0.45  (Less reliance on RGB)
  Feature:  0.20  (Better alignment)
  Sparse:   0.08
  â†’ Audio becoming more independent

Epoch 100:
  Task:     1.20
  Response: 0.25  (Mostly independent)
  Feature:  0.15
  Sparse:   0.05
  â†’ Audio can work independently!
```

---

## ğŸ¨ Visualization

Training ì‹œ ìƒì„±ë˜ëŠ” ì‹œê°í™”:

```
results/adabins_distill_batvisionv2_BS64_Lr0.001/
â”œâ”€â”€ epoch_0002_distill.png
â”œâ”€â”€ epoch_0004_distill.png
â”œâ”€â”€ ...
â””â”€â”€ best_model.pth
```

ê° ì‹œê°í™” í¬í•¨:
1. **Audio Input**: Spectrogram
2. **RGB Input**: Camera image
3. **GT Depth**: Ground truth
4. **Audio Prediction**: Student's output
5. **RGB Prediction**: Teacher's output (training)
6. **Error Map**: Audio prediction error
7. **Bin Distribution**: Adaptive bins (Audio vs RGB)
8. **Depth Histogram**: Distribution comparison

---

## ğŸ’¡ Tips & Best Practices

### 1. Temperature ì„ íƒ

```python
# Low temperature (T=2): Hard targets
- RGB predictionì„ ê°•í•˜ê²Œ ë”°ë¼í•¨
- ë¹ ë¥¸ ìˆ˜ë ´, ë‚®ì€ flexibility

# Medium temperature (T=4-6): Balanced
- ì ì ˆí•œ soft targets
- ì¶”ì²œ! â­

# High temperature (T=8-10): Very soft
- ë§¤ìš° ë¶€ë“œëŸ¬ìš´ targets
- ë” ë§ì€ exploration
```

### 2. Loss ê°€ì¤‘ì¹˜ íŠœë‹

```bash
# Feature distillation ê°•í™” (early layers ì¤‘ìš”)
--lambda_feature 0.5

# Response distillation ê°•í™” (final output ì¤‘ìš”)
--lambda_response 0.8

# Balanced (ì¶”ì²œ)
--lambda_task 1.0 --lambda_response 0.5 --lambda_feature 0.3
```

### 3. N_bins ì„ íƒ

```bash
# ì ì€ bins (64): ë¹ ë¥¸ í•™ìŠµ, ë‚®ì€ ì •ë°€ë„
--n_bins 64

# ì¤‘ê°„ bins (128): Balanced â­
--n_bins 128

# ë§ì€ bins (256): ë†’ì€ ì •ë°€ë„, ëŠë¦° í•™ìŠµ
--n_bins 256
```

### 4. Debugging

```bash
# Overfitting ì²´í¬
python train_adabins_distillation.py --batch_size 16 --learning_rate 0.0005

# Fast iteration (ì‘ì€ ëª¨ë¸)
python train_adabins_distillation.py --base_channels 32 --n_bins 64

# Full training
python train_adabins_distillation.py --base_channels 64 --n_bins 128 --nb_epochs 200
```

---

## ğŸ“ Files Created

```
models/
â””â”€â”€ adabins_distillation_model.py  # Model architecture
    - AdaBinsEncoder (RGB & Audio)
    - AdaBinsBinPredictor (Adaptive bins)
    - AdaBinsDecoder (Classification)
    - AdaBinsDistillationModel (Full system)

utils_distillation_loss.py         # Loss functions
    - DistillationLoss (Standard)
    - AdaptiveDistillationLoss (Curriculum)

train_adabins_distillation.py      # Training script
    - 3-phase training support
    - W&B integration
    - Visualization

ADABINS_DISTILLATION_GUIDE.md      # This file
```

---

## ğŸ”¬ Advanced Usage

### Pre-trained RGB Encoder

```python
# TODO: Implement in model
# Load pre-trained RGB depth estimation model
model = create_adabins_distillation_model(
    use_pretrained_rgb=True,
    ...
)
```

### Fine-tuning Audio-only

```bash
# Phase 1: Distillation (RGB + Audio)
python train_adabins_distillation.py --experiment_name phase1_distill

# Phase 2: Fine-tune Audio-only (optional)
python train_adabins_distillation.py \
  --checkpoints <last_epoch> \
  --lambda_response 0.0 \
  --lambda_feature 0.0 \
  --experiment_name phase2_audio_only
```

### Multi-GPU Training

```bash
python train_adabins_distillation.py \
  --gpu_ids 0,1,2,3 \
  --batch_size 256
```

---

## â“ FAQ

**Q: RGBê°€ ì—†ìœ¼ë©´ inference ëª»í•˜ë‚˜ìš”?**  
A: ì•„ë‹ˆìš”! InferenceëŠ” audioë§Œ í•„ìš”í•©ë‹ˆë‹¤. RGBëŠ” trainingì—ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.

**Q: AdaBinsê°€ Fixed Binsë³´ë‹¤ ì™œ ì¢‹ë‚˜ìš”?**  
A: ê° ì´ë¯¸ì§€ì˜ depth ë¶„í¬ì— ë§ì¶° binsë¥¼ ì˜ˆì¸¡í•˜ë¯€ë¡œ, ì¢ì€ ë²”ìœ„ì—ì„œëŠ” ë” ì •ë°€í•˜ê³  ë„“ì€ ë²”ìœ„ì—ì„œëŠ” ë” flexibleí•©ë‹ˆë‹¤.

**Q: Base+Residualê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ê°€ìš”?**  
A: Base+Residualì€ regression, AdaBinsëŠ” classificationì…ë‹ˆë‹¤. Classificationì´ ë” ì•ˆì •ì ì´ê³ , RGB knowledgeë¥¼ transferí•˜ê¸° ì‰½ìŠµë‹ˆë‹¤.

**Q: Adaptive lossì™€ standard loss ì°¨ì´ëŠ”?**  
A: Adaptive lossëŠ” epochì— ë”°ë¼ loss ê°€ì¤‘ì¹˜ë¥¼ ìë™ìœ¼ë¡œ ì¡°ì ˆí•©ë‹ˆë‹¤ (curriculum learning).

**Q: BatvisionV1ì—ì„œë„ ì‘ë™í•˜ë‚˜ìš”?**  
A: ë„¤! í•˜ì§€ë§Œ BV1ì€ RGBê°€ ì—†ìœ¼ë¯€ë¡œ, distillation íš¨ê³¼ê°€ ì œí•œì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ¯ Next Steps

1. âœ… **ê¸°ë³¸ í•™ìŠµ**: Standard distillationìœ¼ë¡œ baseline êµ¬ì¶•
2. âœ… **Adaptive í•™ìŠµ**: Curriculum learningìœ¼ë¡œ ì„±ëŠ¥ ê°œì„ 
3. ğŸ”œ **Pre-trained RGB**: ImageNet or NYUv2 pre-trained encoder ì‚¬ìš©
4. ğŸ”œ **Ablation Study**: ê° loss componentì˜ íš¨ê³¼ ë¶„ì„
5. ğŸ”œ **Cross-dataset Transfer**: BV2â†’BV1 transfer learning

---

**Happy Distilling! ğŸ‰**

W&Bì—ì„œ ê²°ê³¼ í™•ì¸: https://wandb.ai/branden/batvision-depth-estimation

