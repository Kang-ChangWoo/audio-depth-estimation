# Base Generalization Update - Critical Fix

## ğŸ¯ í•µì‹¬ ë¬¸ì œ ë°œê²¬

> **"Baseê°€ ì „ì²´ ë°ì´í„°ì…‹ì„ ì¼ë°˜í™”í•  ìˆ˜ ìˆì–´ì•¼ íš¨ê³¼ê°€ ìˆë‹¤"**

ì´ì „ êµ¬í˜„ì—ì„œ Baseì™€ Residual decoderê°€ **ë™ì¼í•œ ìš©ëŸ‰**(6.8M params)ì„ ê°€ì ¸ì„œ:
- Baseê°€ ê° ìƒ˜í”Œì— overfitting (ì¼ë°˜í™” ì‹¤íŒ¨)
- Residualì´ í•  ì¼ì´ ì—†ì–´ì§ (ê³¼ì–µì œ)
- ì„±ëŠ¥ í–¥ìƒ ì—†ìŒ (RMSE ì •ì²´)

---

## âœ… ì ìš©ëœ ìˆ˜ì •ì‚¬í•­

### 1. Base Decoder ìš©ëŸ‰ ëŒ€í­ ì¶•ì†Œ â­â­â­

**Before**:
```python
base_channels = 64
Base Decoder: 64 â†’ 128 â†’ 256 â†’ 512 channels
Parameters: ~6.8M (Residualê³¼ ë™ì¼)
```

**After**:
```python
base_ch = base_channels // 4  # 16 channels
Base Decoder: 16 â†’ 32 â†’ 64 â†’ 128 channels
Parameters: ~0.4M (Residualì˜ 1/17)
```

**íš¨ê³¼**: 
- âœ… Baseê°€ ì„¸ë¶€ì‚¬í•­ì„ memorize ëª»í•¨ â†’ **ì¼ë°˜í™” ê°•ì œ**
- âœ… BaseëŠ” ëŒ€ëµì ì¸ êµ¬ì¡°ë§Œ í•™ìŠµ
- âœ… Residualì´ ì„¸ë¶€ì‚¬í•­ ë‹´ë‹¹

---

### 2. Loss ê°€ì¤‘ì¹˜ ì¬ì¡°ì •

#### BaseResidualLoss (ê¸°ë³¸):
```python
# Before
lambda_base = 0.8
lambda_sparse = 0.2

# After
lambda_base = 1.2    # 50% ì¦ê°€ - Base í•™ìŠµ ê°•í™”
lambda_sparse = 0.05  # 75% ê°ì†Œ - Residual ììœ ë¡­ê²Œ
```

#### AdaptiveBaseResidualLoss (Curriculum):
```python
# Before
lambda_recon_init = 0.5
lambda_base_init = 1.5
lambda_sparse = 0.3
warmup_epochs = 20

# After
lambda_recon_init = 0.3   # Base ì¤‘ì‹¬ í•™ìŠµ
lambda_base_init = 2.0    # Base ê°•í™”
lambda_sparse = 0.05      # Residual ì–µì œ ì™„í™”
warmup_epochs = 50        # Baseê°€ ì¶©ë¶„íˆ ì¼ë°˜í™”
```

**íš¨ê³¼**:
- âœ… Baseê°€ ë¨¼ì € ì¼ë°˜í™”ëœ êµ¬ì¡° í•™ìŠµ
- âœ… Residualì´ ì ì ˆíˆ í™œì„±í™” (sparse_loss 0.2~0.4 ì˜ˆìƒ)
- âœ… Epoch 50ê¹Œì§€ Base ì¤‘ì‹¬, ì´í›„ Residual refinement

---

### 3. Residual ë²”ìœ„ í™•ëŒ€

```python
# Before
residual = tanh(...) * (max_depth * 0.2)  # Â±20%

# After
residual = tanh(...) * (max_depth * 0.3)  # Â±30%
```

**ì´ìœ **: Base ìš©ëŸ‰ì´ ì¤„ì—ˆìœ¼ë‹ˆ Residualì´ ë” ë§ì€ ì—­í• 

---

## ğŸ“Š ì˜ˆìƒ íš¨ê³¼

### Architecture ë¹„êµ

| Component | Before | After | ë¹„ìœ¨ |
|-----------|--------|-------|------|
| Base Decoder | 6.8M params | 0.4M params | 1/17 |
| Residual Decoder | 6.8M params | 6.8M params | 1x |
| **Total** | 25.9M | 19.5M | **-25%** |

### í•™ìŠµ íŒ¨í„´ ë³€í™”

#### Before (ë¬¸ì œ):
```
Epoch 10: sparse=0.04  â†’ Residual ê±°ì˜ 0
          Base â‰ˆ Final â†’ Baseê°€ ëª¨ë“  ê²ƒ í•™ìŠµ ì‹œë„
          Val RMSE: 2.6 (ì •ì²´)
```

#### After (ì˜ˆìƒ):
```
Epoch 10: sparse=0.3   â†’ Residual í™œë°œ
          Base â‰  Final â†’ ëª…í™•í•œ ì—­í•  ë¶„ë‹´
          Val RMSE: 2.2 (ê°œì„ !)
          
Epoch 50: Base ê³ ì •   â†’ ì¼ë°˜í™”ëœ êµ¬ì¡° ì™„ì„±
          Residualë§Œ í•™ìŠµ â†’ ì„¸ë¶€ì‚¬í•­ refine
          Val RMSE: 1.8 (ëª©í‘œ!)
```

---

## ğŸ“ ì´ë¡ ì  ë°°ê²½

### PCA/SVD Decomposition

```
Depth = Base_generalized + Residual_specific

Base (Low-rank):
- ì „ì²´ ë°ì´í„°ì…‹ì˜ ì£¼ìš” ì„±ë¶„
- ëª¨ë“  ìƒ˜í”Œì— ê³µí†µ
- ì ì€ íŒŒë¼ë¯¸í„°ë¡œ í‘œí˜„ ê°€ëŠ¥
- "í‰ê· ì ì¸ ë°©ì˜ êµ¬ì¡°"

Residual (High-rank):
- ê° ìƒ˜í”Œì˜ ê³ ìœ  íŠ¹ì„±
- ìƒ˜í”Œë³„ë¡œ ë‹¤ë¦„
- ë§ì€ íŒŒë¼ë¯¸í„° í•„ìš”
- "ì´ ë°©ë§Œì˜ íŠ¹ìˆ˜í•œ ë°°ì¹˜"
```

### Capacity vs Generalization

```
High Capacity Base (Before):
â””â”€ Memorization â†’ ê° ìƒ˜í”Œë³„ë¡œ ë‹¤ë¥´ê²Œ í•™ìŠµ
â””â”€ Poor Generalization â†’ ìƒˆ ìƒ˜í”Œì— ì ìš© ì•ˆë¨

Low Capacity Base (After):
â””â”€ Forced Generalization â†’ ê³µí†µ íŒ¨í„´ë§Œ í•™ìŠµ
â””â”€ Better Transfer â†’ ìƒˆ ìƒ˜í”Œì—ë„ ì˜ ì ìš©
```

---

## ğŸš€ ì‹¤í–‰ ëª…ë ¹ì–´

### ê¸°ë³¸ ì„¤ì • (ê°œì„ ëœ ê¸°ë³¸ê°’)

```bash
python train_base_residual.py \
  --dataset batvisionv2 \
  --batch_size 64 \
  --learning_rate 0.001 \
  --experiment_name generalized_v1
```

### Adaptive Loss í¬í•¨ (ê°•ë ¥ ì¶”ì²œ!)

```bash
python train_base_residual.py \
  --dataset batvisionv2 \
  --batch_size 64 \
  --learning_rate 0.001 \
  --use_wandb \
  --use_adaptive_loss \
  --warmup_epochs 50 \
  --experiment_name generalized_adaptive
```

### ì»¤ìŠ¤í…€ ì„¤ì •

```bash
python train_base_residual.py \
  --dataset batvisionv2 \
  --batch_size 64 \
  --learning_rate 0.001 \
  --use_wandb \
  --use_adaptive_loss \
  --lambda_base 2.0 \
  --lambda_sparse 0.05 \
  --warmup_epochs 50 \
  --experiment_name generalized_custom
```

---

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸

### 1. Sparse Loss í™•ì¸

```
Epoch 1-10:  sparse â‰ˆ 0.3~0.4  (Residual í™œë°œ) âœ…
Epoch 50+:   sparse â‰ˆ 0.2~0.3  (ì•ˆì •í™”) âœ…

ë§Œì•½ sparse < 0.1 ì´ë©´:
â†’ lambda_sparseë¥¼ ë” ë‚®ì¶°ì•¼ í•¨ (0.05 â†’ 0.02)
```

### 2. Base vs Final ë¹„êµ

ì‹œê°í™”ì—ì„œ í™•ì¸:
- **Base**: ë§¤ìš° ë¶€ë“œëŸ¬ì›€, ëŒ€ëµì ì¸ êµ¬ì¡°ë§Œ
- **Residual**: ë¬¼ì²´ ê²½ê³„ì—ì„œ Â±ê°’, í‰ê·  0.3~0.5 ì •ë„
- **Final**: Base + ëª…í™•í•œ ë””í…Œì¼

### 3. ì¼ë°˜í™” í™•ì¸

```python
# í•™ìŠµ ì¤‘ ë¡œê·¸:
Epoch 10: base_loss ê°ì†Œ (1.5 â†’ 1.0)  # êµ¬ì¡° í•™ìŠµ
Epoch 50: base_loss ì•ˆì • (0.8 ìˆ˜ì¤€)   # ì¼ë°˜í™” ì™„ë£Œ
Epoch 100: sparse_loss ì ì ˆ (0.2~0.3) # Residual í™œë°œ
```

---

## ğŸ” Validation ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1 (Epoch 1-20): Base í•™ìŠµ

- [ ] Base loss ë¹ ë¥´ê²Œ ê°ì†Œ
- [ ] Sparse loss 0.3~0.4 ìœ ì§€
- [ ] Base depthê°€ ë¶€ë“œëŸ¬ì›€
- [ ] Val RMSE ì„œì„œíˆ ê°œì„ 

### Phase 2 (Epoch 20-50): í†µí•© í•™ìŠµ

- [ ] Base loss ì•ˆì •í™”
- [ ] Sparse loss ì„œì„œíˆ ê°ì†Œ (0.3 â†’ 0.2)
- [ ] Residualì´ ë””í…Œì¼ í•™ìŠµ ì‹œì‘
- [ ] Val RMSE ì§€ì† ê°œì„ 

### Phase 3 (Epoch 50+): Residual Refinement

- [ ] Base ê³ ì • (detached)
- [ ] Residualë§Œ í•™ìŠµ
- [ ] Sparse loss 0.2~0.3 ìœ ì§€
- [ ] Val RMSE ìµœì¢… ìˆ˜ë ´

---

## ğŸ’¡ ì„±ê³µ ì§€í‘œ

### Minimum Requirements

- âœ… Sparse loss > 0.15 (Residualì´ í™œë°œ)
- âœ… Base depthê°€ ë¶€ë“œëŸ½ê³  ì¼ë°˜í™”ë¨
- âœ… Val RMSE < 2.2 (ê¸°ì¡´ ëŒ€ë¹„ 15% ê°œì„ )
- âœ… Delta1 > 0.45 (ì •í™•ë„ í–¥ìƒ)

### Ideal Results

- ğŸ¯ Sparse loss â‰ˆ 0.2~0.3 (ê· í˜•)
- ğŸ¯ Base depthê°€ ëª¨ë“  ìƒ˜í”Œì— ë¹„ìŠ·í•œ êµ¬ì¡°
- ğŸ¯ Val RMSE < 1.8 (ê¸°ì¡´ ëŒ€ë¹„ 30% ê°œì„ )
- ğŸ¯ Delta1 > 0.55 (ë†’ì€ ì •í™•ë„)

---

## ğŸ› ë¬¸ì œ í•´ê²°

### ë¬¸ì œ 1: Sparseê°€ ì—¬ì „íˆ ë„ˆë¬´ ì‘ìŒ (< 0.1)

**í•´ê²°**:
```bash
--lambda_sparse 0.02  # ë” ë‚®ì¶¤
--lambda_base 1.5     # Baseë¥¼ ì•½ê°„ ì•½í™”
```

### ë¬¸ì œ 2: Val RMSEê°€ ì´ˆê¸°ì— ë†’ìŒ

**ì •ìƒ**: Baseê°€ ì¶©ë¶„íˆ ì¼ë°˜í™”ë˜ê¸° ì „ê¹Œì§€ëŠ” ë†’ì„ ìˆ˜ ìˆìŒ
- Epoch 20ê¹Œì§€ ê¸°ë‹¤ë¦¬ê¸°
- ê·¸ í›„ì—ë„ 2.8 ì´ìƒì´ë©´ ë¬¸ì œ

### ë¬¸ì œ 3: Baseì™€ Finalì´ ë„ˆë¬´ ë‹¤ë¦„

**í•´ê²°**:
```bash
--lambda_base 2.5  # Base loss ë” ê°•í™”
--warmup_epochs 60  # ë” ê¸´ warmup
```

---

## ğŸ“ ë³€ê²½ëœ íŒŒì¼

1. âœ… `models/base_residual_model.py`
   - Base decoder: 64 â†’ 16 channels (1/4 ìš©ëŸ‰)
   - Residual ë²”ìœ„: 20% â†’ 30%

2. âœ… `utils_base_residual_loss.py`
   - BaseResidualLoss: lambda_base=1.2, lambda_sparse=0.05
   - AdaptiveLoss: init_base=2.0, sparse=0.05, warmup=50

3. âœ… `train_base_residual.py`
   - ê¸°ë³¸ê°’: lambda_base=1.2, lambda_sparse=0.05, warmup=50

---

## ğŸ¯ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

**ë¬¸ì œ**: Baseì™€ Residualì´ ê°™ì€ ìš©ëŸ‰ â†’ Baseê°€ ì¼ë°˜í™” ì‹¤íŒ¨

**í•´ê²°**: Base ìš©ëŸ‰ 1/17ë¡œ ì¶•ì†Œ â†’ **ê°•ì œ ì¼ë°˜í™”**

**ê²°ê³¼**: 
- Base = ì „ì²´ ë°ì´í„°ì…‹ì˜ "í‰ê·  êµ¬ì¡°"
- Residual = ê° ìƒ˜í”Œì˜ "ê³ ìœ  íŠ¹ì„±"
- ëª…í™•í•œ ì—­í•  ë¶„ë‹´ â†’ ì„±ëŠ¥ í–¥ìƒ!

---

**ì´ì œ ì§„ì§œ ì‘ë™í•  ê²ƒì…ë‹ˆë‹¤!** ğŸš€

ëª¨ë‹ˆí„°ë§í•˜ë©´ì„œ sparse lossê°€ 0.2~0.3 ìˆ˜ì¤€ì„ ìœ ì§€í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!

